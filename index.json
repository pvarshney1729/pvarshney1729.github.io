
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a Research Associate in the Machine Learning and Optimization (MLO) team at Google Research India , working with Dr. Prateek Jain and Dr. Abhradeep Thakurta towards privacy-preserving optimization methods. I am broadly interested in developing robust machine learning methods and their mathematical foundations for scientific applications.\nIn May 2021, I graduated from the Indian Institute of Technology Kanpur (IIT Kanpur) with a B.Tech. in Computer Science and Engineering and a Minor in Cognitive Science. During my undergraduate studies, I have had the fortune to work with some of the best scientific minds around the globe. As part of E3@EPFL, I worked with Dr. Grigoris Chrysios and Prof. Volka Cevher in the previous summers on combining Unsupervised Domain Adaptation (UDA) and Class Incremental (CI) learning methods to improve the generalizability of classifiers. As an S.N. Bose Scholar, I worked with Dr. Florian Schafer and Prof. Animashree Anandkumar at Caltech during the summers of 2020 on the intersection of Game Theory/Mechanism Design and Deep Learning to develop zero-sum game strategies and obtain robust classifer models. Around the same time, I interned as a Software Engineer with Microsoft India for which I received a Pre-placement Offer (PPO). In the summer of 2019 summers, I worked under Prof. Djordje Jevdjic at the National University of Singapore (NUS) on a DNA-based archival storage tool, with a specific focus on designing and implementing a robust sub-quadratic time Clustering Algorithm.\nI also spend time as a sign language interpreter and mentor people from the deaf and mute community on matters of financial planning.\n","date":1654128000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1654128000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://example.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Research Associate in the Machine Learning and Optimization (MLO) team at Google Research India , working with Dr. Prateek Jain and Dr. Abhradeep Thakurta towards privacy-preserving optimization methods.","tags":null,"title":"Prateek Varshney","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://example.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Prateek Varshney","Abhradeep Thakurta","Prateek Jain"],"categories":null,"content":" ","date":1654128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654128000,"objectID":"5683c8f1d70593258850cc6a2fb1accd","permalink":"https://example.com/publication/dp-ssgd/","publishdate":"2022-06-02T00:00:00Z","relpermalink":"/publication/dp-ssgd/","section":"publication","summary":"We study the problem of differentially private linear regression where each of the data point is sampled from a fixed sub-Gaussian style distribution. We propose and analyze a one-pass mini-batch stochastic gradient descent method (DP-AMBSSGD) where points in each iteration are sampled without replacement. Noise is added for DP but the noise standard deviation is estimated online. Compared to existing {{\u003c math \u003e}}$(œµ,Œ¥)$ {{\u003c math \u003e}}-DP techniques which have sub-optimal error bounds, DP-AMBSSGD is able to provide nearly optimal error bounds in terms of key parameters like dimensionality {{\u003c math \u003e}}$d$ {{\u003c math \u003e}}, number of points {{\u003c math \u003e}}$N$ {{\u003c math \u003e}}, and the standard deviation {{\u003c math \u003e}}$\\sigma$ {{\u003c math \u003e}} of the noise in observations. For example, when the {{\u003c math \u003e}}$d$ {{\u003c math \u003e}}-dimensional covariates are sampled i.i.d. from the normal distribution, then the excess error of DP-AMBSSGD due to privacy is {{\u003c math \u003e}}$\\frac{œÉ^2d}{N}(1+\\frac{d}{\\epsilon^2N}) ${{\u003c math \u003e}}, i.e., the error is meaningful when number of samples {{\u003c math \u003e}}$N = \\Omega (d \\log d)${{\u003c math \u003e}} which is the standard operative regime for linear regression. In contrast, error bounds for existing efficient methods in this setting are {{\u003c math \u003e}}$:\\mathcal{O}\\Big(\\frac{d^3}{\\epsilon^2N^2}\\Big)${{\u003c /math \u003e}}, even for {{\u003c math \u003e}}$\\sigma=0${{\u003c math \u003e}}. That is, for constant {{\u003c math \u003e}}$\\epsilon${{\u003c math \u003e}}, the existing techniques require {{\u003c math \u003e}}$N=\\Omega(d^{1.5})${{\u003c math \u003e}} to provide a non-trivial result.","tags":[],"title":"(Nearly) Optimal Private Linear Regression for Sub-Gaussian Data via Adaptive Clipping","type":"publication"},{"authors":null,"categories":null,"content":"Supervisor: Prof. Dootika Vats, IIT Kanpur.\nWe Explored the avenues of variance reduction methods such as Control Variates and their applications to Stochastic Gradient based Langevin Dynamics (SGLD), MCMC (SGMCMC) and Hamiltonian Monte Carlo (SGHMC) techniques. In this report, we mainly focused on reproducing and extending the results of two papers: ‚ÄúVariance Reduction for Stochastic Gradient Optimisation‚Äù (Wang et. al. (2013)) and ‚ÄúControl Variates for Stochastic Gradient MCMC‚Äù (Baker et. al. (2019)) and explored their theoretical aspects. We extended the notion of Control Variates to different settings such as Metropolis-adjusted Langevin algorithm (MALA) explored how these ideas can be adopted and improved in these settings.\n","date":1619481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619481600,"objectID":"682ca0f55de744ccc72ea9d3658be462","permalink":"https://example.com/project/monte-carlo-/","publishdate":"2021-04-27T00:00:00Z","relpermalink":"/project/monte-carlo-/","section":"project","summary":"Supervisor: Prof. Dootika Vats, IIT Kanpur.\nWe Explored the avenues of variance reduction methods such as Control Variates and their applications to Stochastic Gradient based Langevin Dynamics (SGLD), MCMC (SGMCMC) and Hamiltonian Monte Carlo (SGHMC) techniques.","tags":["Monte Carlo Markov Chain"],"title":"Control Variates for Stochastic Gradient Hamiltonian Monte Carlo","type":"project"},{"authors":null,"categories":null,"content":"Supervisor: Prof. Vipul Arora, IIT Kanpur.\nIn this term report we presented our model for the speaker diarization problem and explained how one can leverage Transfer Learning to quickly learn a model at the expense of negligible performance loss as compared to a fully trained one. Given the input utterances and their speaker identity labels, we extracted embeddings from short audio segments and used these embeddings to segregate the speaker segments within the input source. Building upon this model, we focused on transfer learning and manually adapting over various datasets so as to make our model more generic. We also focused on improving the DER along with experimenting with different embedding generation networks.\n","date":1618876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618876800,"objectID":"9a1b35fbce72d1f3fc7d0b08b4a13065","permalink":"https://example.com/project/comparison-of-sgd-variants-for-stochastic-optimization/","publishdate":"2021-04-20T00:00:00Z","relpermalink":"/project/comparison-of-sgd-variants-for-stochastic-optimization/","section":"project","summary":"Supervisor: Prof. Vipul Arora, IIT Kanpur.\nIn this term report we presented our model for the speaker diarization problem and explained how one can leverage Transfer Learning to quickly learn a model at the expense of negligible performance loss as compared to a fully trained one.","tags":["Speech Signal Processing"],"title":"Speaker Diarization","type":"project"},{"authors":["Prateek Varshney","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://example.com/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":null,"categories":null,"content":"Supervisor: Prof. Ketan Rejawat, IIT Kanpur.\nIn this term report we eproduced and extended the empirical results of ‚ÄúOn the Insufficiency of Existing Momentum Schemes for Stochastic Optimization‚Äù and ‚ÄùAccelerating Stochastic Gradient Descent For Least Squares Regression‚Äù by Kidambi et al. We showed experimentally that there exist simple stochastic problem instances where momentum based methods are sub-optimal and enjoy practical gains over SGD in deep learning applications due to minibatching and also established that ASGD and Adam can converge faster than all other methods irrespective of batch sizes\n","date":1592524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592524800,"objectID":"f11b3795b68414d9a1e036c799c852ee","permalink":"https://example.com/project/speaker-diarization/","publishdate":"2020-06-19T00:00:00Z","relpermalink":"/project/speaker-diarization/","section":"project","summary":"Supervisor: Prof. Ketan Rejawat, IIT Kanpur.\nIn this term report we eproduced and extended the empirical results of ‚ÄúOn the Insufficiency of Existing Momentum Schemes for Stochastic Optimization‚Äù and ‚ÄùAccelerating Stochastic Gradient Descent For Least Squares Regression‚Äù by Kidambi et al.","tags":["Optimization Theory"],"title":"Comparing different SGD variants for online optimization","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://example.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Soumya Ranjan Dash","Sandeep Routray","Prateek Varshney","Ashutosh Modi"],"categories":null,"content":" ","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"1a6c7ceea85831f8bab4c810787a1bbf","permalink":"https://example.com/publication/sem-eval/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/publication/sem-eval/","section":"publication","summary":"In this paper, we describe our system for Task 4 of SemEval 2020, which involves differentiating between natural language statements that confirm to common sense and those that do not. The organizers propose three subtasks - first, selecting between two sentences, the one which is against common sense. Second, identifying the most crucial reason why a statement does not make sense. Third, generating novel reasons for explaining the against common sense statement. Out of the three subtasks, this paper reports the system description of subtask A and subtask B. This paper proposes a model based on transformer neural network architecture for addressing the subtasks. The novelty in work lies in the architecture design, which handles the logical implication of contradicting statements and simultaneous information extraction from both sentences. We use a parallel instance of transformers, which is responsible for a boost in the performance. We achieved an accuracy of 94.8% in subtask A and 89% in subtask B on the test set.","tags":[],"title":"CS-NET at SemEval-2020 Task 4: Siamese BERT for ComVE","type":"publication"}]